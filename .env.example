# =============================================================================
# Document Ingestion API Configuration Template
# =============================================================================
# Copy this file to .env and modify the values according to your environment
# 
# Usage: cp .env.example .env
#
# For detailed configuration options, see: docs/MODELS.md

# =============================================================================
# DEVICE AND MODEL CONFIGURATION
# =============================================================================

# Processing device: cpu, cuda (NVIDIA GPU), or mps (Apple Silicon)
DEVICE=cpu

# Base directory for all models (will be created if doesn't exist)
MODELS_DIR=models

# Individual model directories (relative to MODELS_DIR)
EASYOCR_MODELS_DIR=models/EasyOcr
CODE_FORMULA_MODEL_DIR=models/ds4sd--CodeFormula
FIGURE_CLASSIFIER_MODEL_DIR=models/ds4sd--DocumentFigureClassifier
LAYOUT_MODEL_DIR=models/ds4sd--docling-models

# OCR Engine: easyocr (more accurate) or tesseract (faster)
DEFAULT_OCR_ENGINE=easyocr

# Force OCR on all pages (slower but more thorough)
FORCE_FULL_PAGE_OCR=False

# =============================================================================
# HUGGING FACE CONFIGURATION
# =============================================================================

# Set to True for offline operation (after models are downloaded)
TRANSFORMERS_OFFLINE=True
HF_DATASETS_OFFLINE=True

# HuggingFace cache directories (should match MODELS_DIR)
HF_HOME=models
HF_HUB_CACHE=models

# =============================================================================
# DOCUMENT CHUNKING CONFIGURATION
# =============================================================================

# Maximum tokens per chunk (adjust based on your use case)
# - Small chunks (500-1000): Better precision, more chunks
# - Large chunks (4000-8000): Better context, fewer chunks
CHUNK_SIZE=6500

# Token overlap between chunks (typically 20-25% of CHUNK_SIZE)
CHUNK_OVERLAP=1640

# Tokenizer model for chunking (must match downloaded model)
CHUNKER_TOKENIZER=models/nomic-embed-text-v1.5
TOKENIZER_MODEL_DIR=models/nomic-embed-text-v1.5

# Merge similar adjacent chunks
MERGE_PEERS=True

# =============================================================================
# API CONFIGURATION
# =============================================================================

# API metadata
API_TITLE=Document Ingestion API
API_VERSION=1.0.0

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Server binding
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# Development settings
SERVER_RELOAD=false
SERVER_LOG_LEVEL=info

# Production settings (set to number of CPU cores for production)
SERVER_WORKERS=1

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log levels: debug, info, warning, error, critical
CELERY_WORKER_LOG_LEVEL=info
ASR_LOG_LEVEL=info
PIPELINE_LOG_LEVEL=info
PROCESSING_LOG_LEVEL=info

# =============================================================================
# CORS CONFIGURATION
# =============================================================================

# Allowed origins (* for all, or comma-separated list)
# Examples:
# - Development: *
# - Production: https://yourdomain.com,https://app.yourdomain.com
CORS_ORIGINS=*

# Allow credentials in CORS requests
CORS_CREDENTIALS=true

# =============================================================================
# CELERY AND REDIS CONFIGURATION
# =============================================================================

# Redis connection for Celery broker and results
# Format: redis://[username:password@]host:port/database
# Default Redis installation: redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/9
CELERY_RESULT_BACKEND=redis://localhost:6379/10

# =============================================================================
# WORKER CONFIGURATION
# =============================================================================

# Start embedded Celery worker with API server
START_CELERY_WORKER=true

# Worker performance settings
CELERY_WORKER_PREFETCH_MULTIPLIER=1

# Task timeout settings (in seconds)
CELERY_TASK_SOFT_TIME_LIMIT=900   # 15 minutes soft limit
CELERY_TASK_TIME_LIMIT=1200       # 20 minutes hard limit

# =============================================================================
# PYTHON PATH CONFIGURATION
# =============================================================================

# Add project directory to Python path (adjust to your installation path)
# This should be the absolute path to the doc-ingestion directory
PYTHONPATH=/path/to/your/doc-ingestion

# =============================================================================
# SPEECH RECOGNITION (ASR) CONFIGURATION
# =============================================================================

# Language code for speech recognition (id=Indonesian, en=English)
ASR_LANGUAGE=id

# Whisper model configuration
WHISPER_MODEL_DIR=models/cahya--whisper-medium-id
WHISPER_MODEL_NAME=cahya/whisper-medium-id

# Whisper processing parameters
WHISPER_MAX_NEW_TOKENS=420
WHISPER_CHUNK_DURATION=30.0
WHISPER_CHUNK_OVERLAP=2.0

# =============================================================================
# ENVIRONMENT-SPECIFIC EXAMPLES
# =============================================================================

# Development Environment Example:
# DEVICE=cpu
# SERVER_RELOAD=true
# SERVER_LOG_LEVEL=debug
# TRANSFORMERS_OFFLINE=False
# START_CELERY_WORKER=true

# Production Environment Example:
# DEVICE=cuda
# SERVER_RELOAD=false
# SERVER_LOG_LEVEL=warning
# SERVER_WORKERS=4
# TRANSFORMERS_OFFLINE=True
# START_CELERY_WORKER=false
# CORS_ORIGINS=https://yourdomain.com

# High-Performance Environment Example:
# DEVICE=cuda
# CHUNK_SIZE=8000
# CHUNK_OVERLAP=2000
# CELERY_WORKER_PREFETCH_MULTIPLIER=2
# DEFAULT_OCR_ENGINE=tesseract
# FORCE_FULL_PAGE_OCR=True

# Low-Memory Environment Example:
# DEVICE=cpu
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=200
# CELERY_WORKER_PREFETCH_MULTIPLIER=1
# FORCE_FULL_PAGE_OCR=False